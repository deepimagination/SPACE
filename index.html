<!doctype html>
<html lang="en">

<head>
    <!-- <meta charset="utf-8"> -->
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="data/favicon.ico">

    <title>SPACEx</title>

    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
        integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">


    <!-- Custom styles for this template -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro">
    <link rel="dns-prefetch" href="//cdn.jsdelivr.net" />
    <link href="https://cdn.jsdelivr.net/npm/prismjs/themes/prism.min.css" rel="stylesheet" />
    <link href="https://cdn.jsdelivr.net/gh/jablonczay/code-box-copy/code-box-copy/css/code-box-copy.min.css"
        rel="stylesheet" />

    <!-- Global site tag (gtag.js) - Google Analytics -->


    <style>
        body {
            font-family: 'Source Sans Pro', sans-serif;
            padding-bottom: 50px;
        }

        th {
            width: 20%;
            /* height: 200px; */
            display: table-cell;
            padding: 0;
            margin: 0;
        }

        td {
            padding: 0;
            width: 20%;
            /* height: 200px; */
            margin: 0;
            /* display: inline; */
        }


        /* table {
      border-collapse: collapse;
      border-spacing: 0;
    } */

        hr {
            background: #80808083;
        }

        .embed-responsive-2by1 {
            padding-bottom: 50%;
        }

        .embed-responsive-4by1 {
            padding-bottom: 25%;
        }

        .embed-responsive-6by1 {
            padding-bottom: 16.67%;
        }

        .embed-responsive-8by1 {
            padding-bottom: 12.50%;
        }

        .embed-responsive-teaser {
            padding-bottom: 29%;
        }

        .float-button {
            position: fixed;
            right: 1%;
            z-index: 9999;
        }

        .vert {
            transform-origin: 50% 50%;
            transform: rotate(180deg);
            writing-mode: vertical-rl;
            margin: 0;
            margin-left: auto;
            margin-right: 0;
        }

        .caption {
            font-size: 0.9rem;
            margin-top: 0;
            margin-bottom: 5px;
            font-weight: bold;
        }

        .w-85 {
            width: 85% !important;
        }

        img {
            width: 100%;
            padding: 0;
            margin: 0;
        }

        video {
            width: 100%;
            padding: 0;
            margin: 0;
        }
    </style>
</head>

<body>
        <main role="main">
            <section class="jumbotron text-center" style="padding: 2%; padding-bottom: 1%; background-color: #e6e9ec;">
                <div class="container">
                    <h2 class="jumbotron-heading">SPACEx <img src="data/assets/rocket.png" / style="height: 1.5em; width: auto;">:
                        Speech-driven Portrait Animation with Controllable Expression</h2>
                </div>

                <div class="container">
                    <div class="row">
                        <div class="col-md">
                            <h5 id="authors" class="text-center" style="margin: 0px;"><a class="text-center"
                                    href="https://research.nvidia.com/person/siddharth-gururani/" target="_blank">Siddharth Gururani<span
                                        style="color: #76b900;"></span></a></h5>
                        </div>
                        <div class="col-md">
                            <h5 id="authors" class="text-center" style="margin: 0px;"><a class="text-center"
                                    href="http://arunmallya.github.io/" target="_blank">Arun Mallya<span
                                        style="color: #76b900;"></span></a></h5>
                        </div>
                        <div class="col-md">
                            <h5 id="authors" class="text-center" style="margin: 0px;"><a class="text-center"
                                    href="https://tcwang0509.github.io/" target="_blank">Ting-Chun Wang<span
                                        style="color: #76b900;"></span></a></h5>
                        </div>
                        <div class="col-md">
                            <h5 id="authors" class="text-center" style="margin: 0px;"><a class="text-center"
                                    href="https://rafaelvalle.github.io/" target="_blank">Rafael Valle<span
                                        style="color: #76b900;"></span></a></h5>
                        </div>
                        <div class="col-md">
                            <h5 id="authors" class="text-center" style="margin: 0px;"><a class="text-center"
                                    href="http://mingyuliu.net/" target="_blank">Ming-Yu Liu<span
                                        style="color: #76b900;"></span></a></h5>
                        </div>
                    </div>
                    <div class="row" style="margin-top:0.75%; margin-left: auto; margin-right: auto;width: 50%;">
                        <div class="col-md">
                            <h5 style="color: #76b900; margin-bottom: 0;"><a class="text-center"
                                    href="https://www.nvidia.com/en-us/research/" target="_blank"
                                    style="color: #76b900;"><b>NVIDIA</b></a></h5>
                        </div>
                    </div>
                </div>


                <div class="buttons">
                    <a href="https://arxiv.org/abs/2210.01794" target="_blank" class="btn btn-primary my-2">Paper</a>
                    <!-- <a href="video_viewer.html" target="_blank" class="btn btn-secondary my-2"
                        style="background-color: #75b900c0;">Additional results</a> -->
                    </p>
                </div>

                <div class="container" style="max-width: 900px;">
                    <div class="row">
                        <div class="col-md">
                            <p>
                                We present <b style="color: #76b900;">SPACEx</b>, which uses speech and a single image to generate high-resolution, and expressive videos with realistic head pose, without requiring a driving video. It uses a multi-stage approach, combining the controllability of facial landmarks with the high-quality synthesis power of a pretrained face generator. <b style="color: #76b900;">SPACEx</b> also allows for the control of emotions and their intensities. Our method outperforms prior methods in objective metrics for image quality and facial motions and is strongly preferred by users in pair-wise comparisons.
                            </p>
                        </div>
                    </div>
                    <br>
                    <div class="col-md-12">
                        <h6 class="text-center"><b>Speech-driven animation of a portrait, with control over the output pose, emotions, and intensities of expressions</b></h6>
                    </div>
                    <table>
                        <tr>
                            <th style="text-align: right; width: 8%;">Pose&nbsp;&nbsp;&nbsp;&nbsp;</th>
                            <td>Generated</td>
                            <td>Transferred</td>
                            <td>Generated</td>
                            <td>Generated</td>
                        </tr>
                        <tr>
                            <th style="text-align: right; width: 8%;">Emotion&nbsp;&nbsp;&nbsp;&nbsp;</th>
                            <td>Neutral</td>
                            <td>Neutral</td>
                            <td>Happy</td>
                            <td>Surprise</td>
                        </tr>
                        <tr>
                            <td style="text-align: right; width: 8%;"></td>
                            <td colspan="4">
                                <video controls   style="vertical-align: top;">
                                    <source
                                        src="data/teaser/image_id03862-JPpFLTSa6iU-00182_audio_id04295-7_t4qaydG3Y-00026.mp4"
                                        type="video/mp4">
                                </video>
                            </td>
                        </tr>
                        <tr>
                            <td style="text-align: right; width: 8%;"></td>
                            <td colspan="4">
                                <video controls   style="vertical-align: top;">
                                    <source src="data/teaser/image_woman_audio_id04570-9dAsIrZc5RY-00077.mp4" type="video/mp4">
                                </video>
                            </td>
                        </tr>
                        <tr>
                            <th style="text-align: right; width: 8%;">Emotion&nbsp;&nbsp;&nbsp;&nbsp;</th>
                            <td>Neutral</td>
                            <td>Neutral</td>
                            <td>Sad</td>
                            <td>Fear</td>
                        </tr>
                        <tr>
                            <th style="text-align: right; width: 8%;">Pose&nbsp;&nbsp;&nbsp;&nbsp;</th>
                            <td>Generated</td>
                            <td>Transferred</td>
                            <td>Generated</td>
                            <td>Generated</td>
                        </tr>
                    </table>

                    <div class="col-md-12">
                    </div>
                </div>
            </section>
        </main>

        <!-- TL;DR floating button -->
        <div class="float-button">
            <p class="float-right">
                <a href="#Summary">TL;DR</a>
            </p>
        </div>

        <!-- Summary video -->
        <!-- 
        <div class="container" style="max-width: 800px;">
            <h5 class="text-center">ICCV 2021 Oral Presentation Video</h5>
            <div class="embed-responsive embed-responsive-16by9" style="margin: 0;">
                <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/5K-AgDmCtt0"
                    allowfullscreen></iframe>
            </div>
            </br>
            <h5 class="text-center">Previous Summary Video</h5>
            <div class="embed-responsive embed-responsive-16by9" style="margin: 0;">
                <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/1Hky092CGFQ?mute=1"
                    allowfullscreen></iframe>
            </div>
            </br>
        </div> 
        -->

        <!-- Overview -->
        <hr style="max-width: 800px;">
        <div class="container" style="max-width: 800px;">
            <div class="row">
                <div class="col-md-12">
                    <h2>Overview</h2>
                    <h5 class="text-center">What exactly is <b style="color: #76b900;">SPACEx</b> trying to solve?</h5>
                    A single image often cannot fully describe the subject due to occlusions, limited pose information,
                    <i>etc</i>. Diverse source images provide more appearance information and reduce the burden of
                    hallucination that an image generator has to perform. Multiple source images provide more complete
                    information, such as the color of the eyes, the texture of the background, <i>etc</i>. This allows
                    for
                    potentially generating an output image that is more faithful to the source setting. Consider the two
                    images shown below. Given just the first image, it is impossible to know what is behind the person.
                    But given the second image, we now know the real background.

                    <div class="text-center" style="color: #76b900;">SPACEx allows you to </div>
                </div>
            </div>
            </br>

            <!-- Issues with prior work. -->
            <div class="row">
                <div class="col-md-12">
                    <hr style="max-width: 800px;">
                    <h5 class="text-center">The "<i>Why don't you just use X?</i> " Question</h5>
                    Single-source-based prior works such as <a
                        href='https://aliaksandrsiarohin.github.io/first-order-model-website/' target='_blank'>FOMM</a>,
                    <a href='https://snap-research.github.io/articulated-animation/' target='_blank'>AA-PCA</a>, and <a
                        href='https://nvlabs.github.io/face-vid2vid/' target='_blank'>fv2v</a> rely on
                    explicit flow-based warping of the source image
                    conditional on the pose of the driving image. Due to this architectural choice, they often have to
                    be modified in ad-hoc ways to take advantage of multiple source images. One scheme is to train an
                    additional pre-processing network to select the most appropriate source image for the given driving
                    image. This would, however, not allow for the use of features from multiple source images at a time.
                    The other possibility is to warp each source image to the driving pose and then average the
                    now-aligned warped features for the generator input. But as is visible in videos below, this leads
                    to sub-optimal results due to the misalignment of warped features and
                    inconsistent predictions across views.
                </div>
            </div>
            </br>
            <table>
                <tr class="text-center">
                    <td>Input image</td>
                    <td><a href="https://hangz-nju-cuhk.github.io/projects/PC-AVS" target='_blank'>PC-AVS</a></td>
                    <td><a href='https://people.umass.edu/~yangzhou/MakeItTalk/' target='_blank'>MakeItTalk</a></td>
                    <td><a href='http://cvit.iiit.ac.in/research/projects/cvit-projects/a-lip-sync-expert-is-all-you-need-for-speech-to-lip-generation-in-the-wild/' target='_blank'>Wav2Lip</a></td>
                    <td><b style="color: #76b900;">SPACEx</b> (ours)</td>
                </tr>
                <tr>
                    <td>
                        <img src="data/comparison/id00419-ag7_GcN_rEM-00314.png">
                    </td>
                    <td colspan="4">
                        <video controls   style="vertical-align: top;">
                            <source src="data/comparison/id00419-ag7_GcN_rEM-00314.mp4"" type="video/mp4">
                        </video>
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="data/comparison/id03789-9alL5EAVFZU-00114.png">
                    </td>
                    <td colspan="4">
                        <video controls   style="vertical-align: top;">
                            <source src="data/comparison/id03789-9alL5EAVFZU-00114.mp4"" type="video/mp4">
                        </video>
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="data/comparison/id04862-4r-u7YAGLoA-00039.png">
                    </td>
                    <td colspan="4">
                        <video controls   style="vertical-align: top;">
                            <source src="data/comparison/id04862-4r-u7YAGLoA-00039.mp4"" type="video/mp4">
                        </video>
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="data/comparison/id08696-_ir7v67UliA-00339.png">
                    </td>
                    <td colspan="4">
                        <video controls   style="vertical-align: top;">
                            <source src="data/comparison/id08696-_ir7v67UliA-00339.mp4"" type="video/mp4">
                        </video>
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="data/comparison/id10306-5jsUg3uxG-E-00005.png">
                    </td>
                    <td colspan="4">
                        <video controls   style="vertical-align: top;">
                            <source src="data/comparison/id10306-5jsUg3uxG-E-00005.mp4"" type="video/mp4">
                        </video>
                    </td>
                </tr>
                <tr class="text-center">
                    <td>Input image</td>
                    <td><a href="https://hangz-nju-cuhk.github.io/projects/PC-AVS" target='_blank'>PC-AVS</a></td>
                    <td><a href='https://people.umass.edu/~yangzhou/MakeItTalk/' target='_blank'>MakeItTalk</a></td>
                    <td><a href='http://cvit.iiit.ac.in/research/projects/cvit-projects/a-lip-sync-expert-is-all-you-need-for-speech-to-lip-generation-in-the-wild/' target='_blank'>Wav2Lip</a></td>
                    <td><b style="color: #76b900;">SPACEx</b> (ours)</td>
                </tr>
            </table>
            </br>
            <div class="row">
                <div class="col-md-12">
                    Comparing the results from different methods, we can immediately notice a few issues:
                    <ul>
                        <li>
                            Methods developed for a single source image, such as <a
                                href='https://nvlabs.github.io/face-vid2vid/' target='_blank'>fv2v</a> and <a
                                href='https://aliaksandrsiarohin.github.io/first-order-model-website/'
                                target='_blank'>FOMM</a> are unable to exactly align features warped from different
                            source images
                        </li>
                        <li>
                            Furthermore, simple averaging of warped features produces artifacts in the output. This is
                            because averaging does not distinguish between ground truth features and hallucinated
                            features.
                        </li>
                    </ul>
                    In the last column, we present results from <b style="color: #76b900;">implicit warping</b>, which
                    solves both issues raised above. The cross-modal attention layer is able to select the
                    appropriate features and produce an output free of artifacts.
                    <br>
                    Additional results and visualizations are available <a style="color: #76b900;"
                        href='video_viewer.html' target='_blank'>at this link</a>.
                </div>
            </div>
            </br>
        </div>

        <!-- Method details. -->
        <hr style="max-width: 800px;">
        <div class="container" style="max-width: 800px;" id="Method">
            <div class="row">
                <div class="col-md-12">
                    <h2>Method</h2>
                    <h5 class="text-center">What makes <b style="color: #76b900;">SPACEx</b> so controllable?</h5>
                    Multi stage - blah blah
                </div>
            </div>
            <br><br>

            <img src="data/method/overview.png">
            <br><br><br><br>

            <table>
                <tr class="text-center">
                    <td></td>
                    <td colspan="3" style="background-color: rgba(128, 128, 128, 0.4);">Intermediate predicted</td>
                    <td></td>
                </tr>
                <tr class="text-center">
                    <td>Input image</td>
                    <td style="background-color: rgba(128, 128, 128, 0.2);">normalized facial landmarks</td>
                    <td style="background-color: rgba(128, 128, 128, 0.2);">posed facial landmarks</td>
                    <td style="background-color: rgba(128, 128, 128, 0.2);">latent face-vid2vid keypoints</td>
                    <td>Animated output</td>
                </tr>
                <tr>
                    <td>
                        <img src="data/intermediates/id00017-M6PYYNz3pac-00033.jpg">
                    </td>
                    <td colspan="4">
                        <video controls   style="vertical-align: top;">
                            <source src="data/intermediates/id00017-M6PYYNz3pac-00033.mp4" type="video/mp4">
                        </video>
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="data/intermediates/id01460-2vJlUcWI2DQ-00012.jpg">
                    </td>
                    <td colspan="4">
                        <video controls   style="vertical-align: top;">
                            <source src="data/intermediates/id01460-2vJlUcWI2DQ-00012.mp4" type="video/mp4">
                        </video>
                    </td>
                </tr>
            </table>

            <div class="row">
                <div class="col-md-12">
                    <hr style="max-width: 800px;">
                    <h5 class="text-center">Emotion control</h5>
                    We use labels and FilM
                </div>
            </div>
            <br><br>

            <table style="width: 80%; margin: auto;">
                <tr class="text-center">
                    <td>Input image</td>
                    <td>0.5 Happy</td>
                    <td>1.0 Happy</td>
                </tr>
                <tr>
                    <td> <img src="data/emotion/source.jpg"> </td>
                    <td colspan="2">
                        <video controls   style="vertical-align: top;"> <source src="data/emotion/video.mp4" type="video/mp4">
                        </video>
                    </td>
                </tr>
                <tr class="text-center">
                    <td>Input image</td>
                    <td>0.5 Angry</td>
                    <td>1.0 Angry</td>
                </tr>
            </table>
        </div>

        <!-- Summary. -->
        <hr style="max-width: 800px;">
        <div class="container" style="max-width: 800px;" id="Summary">
            <div class="row">
                <div class="col-md-12">
                    <h2>Summary</h2>
                    <ul>
                        <li>GANcraft is a powerful tool for converting semantic block worlds to photorealistic
                            worlds
                            without the need for ground truth data.</li>
                        <li>Existing methods perform poorly on the task due to the lack of viewpoint consistency and
                            photorealism.</li>
                        <li>GANcraft performs well in this challenging world-to-world setting where the ground truth
                            is
                            unavailable and the distribution mismatch between a Minecraft world and internet photos
                            is
                            significant.</li>
                        <li>We introduce a new training scheme which uses pseudo-ground truth. This improves the
                            quality
                            of the results significantly.</li>
                        <li>We introduce a hybrid neural rendering pipeline which is able to represent large and
                            complex
                            scenes efficiently.</li>
                        <li>We are able to control the appearance of the GANcraft results by using
                            style-conditioning
                            images.</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Citation. -->
        <hr style="max-width: 800px;">
        <div class="container" style="max-width: 800px;">
            <div class="row">
                <div class="col-md-12">
                    <h2>Citation</h2>
                </div>
            </div>
            <div class="code-box-copy" style="font-size: 0.9rem !important; max-width: 800px; margin: 0 auto;">
                <button class="code-box-copy__btn" data-clipboard-target="#citation" title="Copy"
                    style="opacity: 1;"></button>
                <pre><code class="language-bib" style="font-size: 0.9rem;" id="citation">@article{gururani2022spacex,
    title={{SPACEx: Speech-driven Portrait Animation with Controllable Expression}},
    author={Siddharth Gururani and Arun Mallya and Ting-Chun Wang and Rafael Valle and Ming-Yu Liu},
    journal={arXiv preprint arXiv:2211.01324},
    year={2022}
}</code></pre>
            </div>
        </div>


        <footer class="text-">
            <div class="container">
                <p class="float-right">
                    <a href="#">Back to top</a>
                </p>
            </div>
        </footer>

        <!-- Bootstrap core JavaScript
        ================================================== -->
        <!-- Placed at the end of the document so the pages load faster -->
        <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
            integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
            crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
            integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
            crossorigin="anonymous"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
            integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
            crossorigin="anonymous"></script>
        <script type="text/javascript" async
            src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
        <script src="https://cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/prismjs/prism.min.js"></script>
        <script
            src="https://cdn.jsdelivr.net/combine/gh/jablonczay/code-box-copy/clipboard/clipboard.min.js,gh/jablonczay/code-box-copy/code-box-copy/js/code-box-copy.min.js"></script>
        <script src="https://saswatpadhi.github.io/prismjs-bibtex/prism-bibtex.min.js"></script>
        <script>
            (function ($) {
                $('.code-box-copy').codeBoxCopy();
            })(jQuery);
        </script>
</body>

</html>
