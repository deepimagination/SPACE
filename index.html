<!doctype html>
<html lang="en">

<head>
    <!-- <meta charset="utf-8"> -->
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="data/favicon.ico">

    <title>SPACE</title>

    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
        integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">


    <!-- Custom styles for this template -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro">
    <link rel="dns-prefetch" href="//cdn.jsdelivr.net" />
    <link href="https://cdn.jsdelivr.net/npm/prismjs/themes/prism.min.css" rel="stylesheet" />
    <link href="https://cdn.jsdelivr.net/gh/jablonczay/code-box-copy/code-box-copy/css/code-box-copy.min.css"
        rel="stylesheet" />

    <style>
        body {
            font-family: 'Source Sans Pro', sans-serif;
            padding-bottom: 50px;
        }

        th {
            width: 20%;
            /* height: 200px; */
            display: table-cell;
            padding: 0;
            margin: 0;
        }

        td {
            padding: 0;
            width: 20%;
            /* height: 200px; */
            margin: 0;
            /* display: inline; */
        }


        /* table {
      border-collapse: collapse;
      border-spacing: 0;
    } */

        hr {
            background: #80808083;
        }

        .embed-responsive-2by1 {
            padding-bottom: 50%;
        }

        .embed-responsive-4by1 {
            padding-bottom: 25%;
        }

        .embed-responsive-6by1 {
            padding-bottom: 16.67%;
        }

        .embed-responsive-8by1 {
            padding-bottom: 12.50%;
        }

        .embed-responsive-teaser {
            padding-bottom: 29%;
        }

        .float-button {
            position: fixed;
            right: 1%;
            z-index: 9999;
        }

        .vert {
            transform-origin: 50% 50%;
            transform: rotate(180deg);
            writing-mode: vertical-rl;
            margin: 0;
            margin-left: auto;
            margin-right: 0;
        }

        .caption {
            font-size: 0.9rem;
            margin-top: 0;
            margin-bottom: 5px;
            font-weight: bold;
        }

        .w-85 {
            width: 85% !important;
        }

        img {
            width: 100%;
            padding: 0;
            margin: 0;
        }

        video {
            width: 100%;
            padding: 0;
            margin: 0;
        }
    </style>
</head>

<body>
    <main role="main">
        <section class="jumbotron text-center" style="padding: 2%; padding-bottom: 1%; background-color: #e6e9ec;">

            <div class="container text-center">
                <h2 class="jumbotron-heading">SPACE <img src="data/assets/rocket.png" /
                        style="height: 1.5em; width: auto;" title="To the moon!">:
                    <b style="color:#76b900">S</b>peech-driven <b style="color:#76b900">P</b>ortrait <b
                        style="color:#76b900">A</b>nimation with <b style="color:#76b900">C</b>ontrollable <b
                        style="color:#76b900">E</b>xpression
                </h2>
            </div>

            <div class="container">
                <div class="row">
                    <div class="col-md">
                        <h5 id="authors" class="text-center" style="margin: 0px;"><a class="text-center"
                                href="https://research.nvidia.com/person/siddharth-gururani/" target="_blank">Siddharth
                                Gururani<span style="color: #76b900;"></span></a></h5>
                    </div>
                    <div class="col-md">
                        <h5 id="authors" class="text-center" style="margin: 0px;"><a class="text-center"
                                href="http://arunmallya.github.io/" target="_blank">Arun Mallya<span
                                    style="color: #76b900;"></span></a></h5>
                    </div>
                    <div class="col-md">
                        <h5 id="authors" class="text-center" style="margin: 0px;"><a class="text-center"
                                href="https://tcwang0509.github.io/" target="_blank">Ting-Chun Wang<span
                                    style="color: #76b900;"></span></a></h5>
                    </div>
                    <div class="col-md">
                        <h5 id="authors" class="text-center" style="margin: 0px;"><a class="text-center"
                                href="https://rafaelvalle.github.io/" target="_blank">Rafael Valle<span
                                    style="color: #76b900;"></span></a></h5>
                    </div>
                    <div class="col-md">
                        <h5 id="authors" class="text-center" style="margin: 0px;"><a class="text-center"
                                href="http://mingyuliu.net/" target="_blank">Ming-Yu Liu<span
                                    style="color: #76b900;"></span></a></h5>
                    </div>
                </div>
                <div class="row" style="margin-top:0.75%; margin-left: auto; margin-right: auto;width: 50%;">
                    <div class="col-md">
                        <h5 style="color: #76b900; margin-bottom: 0;"><a class="text-center"
                                href="https://www.nvidia.com/en-us/research/" target="_blank"
                                style="color: #76b900;"><b>NVIDIA</b></a></h5>
                    </div>
                </div>
            </div>


            <div class="buttons">
                <a href="https://arxiv.org/abs/2211.09809" target="_blank" class="btn btn-primary my-2">Paper
                    (arxiv)</a>
                <!-- <a href="https://www.youtube.com/watch?v=ExeTeSAMR5Q" target="_blank" class="btn btn-secondary my-2"
                    style="background-color: #75b900c0;">Summary video</a> -->
                </p>
            </div>

            <div class="container" style="max-width: 900px;">
                <div class="row">
                    <div class="col-md">
                        <p>
                            We present <b style="color: #76b900;">SPACE</b>, a method for generating high-resolution,
                            expressive videos with realistic head pose, using just speech and a single image.
                            It uses a multi-stage approach, combining the controllability of facial
                            landmarks with the high-quality synthesis power of a pretrained face generator. <b
                                style="color: #76b900;">SPACE</b> also allows for the control of emotions and their
                            intensities. Our method outperforms prior methods in objective metrics for image quality and
                            facial motions and is strongly preferred by users in pair-wise comparisons.
                        </p>
                    </div>
                </div>
                <div class="col-md-12">
                    <h6 class="text-center"><b>Speech-driven animation of a portrait, with control over the output pose,
                            emotions, and intensities of expressions</b></h6>
                </div>
                <table>
                    <tr style="background-color: rgba(255, 149, 0, 0.3)">
                        <th style="text-align: right; width: 8%; background-color: rgba(255, 149, 0, 0.3)">
                            Pose&nbsp;&nbsp;&nbsp;&nbsp;</th>
                        <td>Generated</td>
                        <td>Transferred</td>
                        <td>Generated</td>
                        <td>Generated</td>
                    </tr>
                    <tr style="background-color: rgba(56, 162, 34, 0.3)">
                        <th style="text-align: right; width: 8%; background-color: rgba(56, 162, 34, 0.3)">
                            Emotion&nbsp;&nbsp;&nbsp;&nbsp;</th>
                        <td>Neutral</td>
                        <td>Neutral</td>
                        <td>Happy</td>
                        <td>Surprise</td>
                    </tr>
                    <tr>
                        <td style="text-align: right; width: 8%;"></td>
                        <td colspan="4">
                            <video controls style="vertical-align: top;">
                                <source
                                    src="data/teaser/image_id03862-JPpFLTSa6iU-00182_audio_id04295-7_t4qaydG3Y-00026.mp4"
                                    type="video/mp4">
                            </video>
                        </td>
                    </tr>
                    <tr>
                        <td style="text-align: right; width: 8%;"></td>
                        <td colspan="4">
                            <video controls style="vertical-align: top;">
                                <source src="data/teaser/image_woman_audio_id04570-9dAsIrZc5RY-00077.mp4"
                                    type="video/mp4">
                            </video>
                        </td>
                    </tr>
                    <tr style="background-color: rgba(56, 162, 34, 0.3)">
                        <th style="text-align: right; width: 8%; background-color: rgba(56, 162, 34, 0.3)">
                            Emotion&nbsp;&nbsp;&nbsp;&nbsp;</th>
                        <td>Neutral</td>
                        <td>Neutral</td>
                        <td>Sad</td>
                        <td>Fear</td>
                    </tr>
                    <tr style="background-color: rgba(255, 149, 0, 0.3)">
                        <th style="text-align: right; width: 8%; background-color: rgba(255, 149, 0, 0.3)">
                            Pose&nbsp;&nbsp;&nbsp;&nbsp;</th>
                        <td>Generated</td>
                        <td>Transferred</td>
                        <td>Generated</td>
                        <td>Generated</td>
                    </tr>
                </table>

                <div class="col-md-12">
                </div>
            </div>
        </section>
    </main>

    <!-- TL;DR floating button -->
    <div class="float-button">
        <p class="float-right">
            <a href="#Summary">TL;DR</a>
        </p>
    </div>

    <!-- Summary video -->
    <!-- <div class="container" style="max-width: 800px;">
        <h5 class="text-center">Summary Video</h5>
        <div class="embed-responsive embed-responsive-16by9" style="margin: 0;">
            <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/ExeTeSAMR5Q"
                allowfullscreen></iframe>
        </div>
        </br>
    </div> -->

    <!-- Overview -->
    <hr style="max-width: 800px;">
    <div class="container" style="max-width: 800px;">
        <div class="row">
            <div class="col-md-12">
                <h2>Overview</h2>
                <h5 class="text-center">What exactly is <b style="color: #76b900;">SPACE</b> trying to solve?</h5>
                Speech-driven portrait animation concerns animating a still image of a face using an arbitrary
                input speech signal. This has a wide range of applications, for example, it
                can be used for driving characters in computer games, dubbing in movies,
                and animating avatars for virtual assistance, virtual reality, and telecommunications.
                This is a challenging task &#8212; it has to use the
                provided speech to predict all the nuances in human facial
                expressions while also guaranteeing that the animation looks
                natural, matches what is being said in the speech sample,
                and preserves the per-frame and video quality.

                <div class="text-center" style="color: #76b900;">
                    <b>SPACE allows you to animate a photo using just speech, with unprecedented controllability over
                        outputs</b>
                </div>
            </div>
        </div>
        </br>

        <!-- Issues with prior work. -->
        <div class="row">
            <div class="col-md-12">
                <hr style="max-width: 800px;">
                <h5 class="text-center">The "<i>Why don't you just use X?</i> " Question</h5>
                While previous methods work on frontal-facing and closely-cropped input images, they suffer
                from degraded quality or fail for arbitrary poses and larger
                crops. Since we predict mouth motions in the normalized
                landmark space and then apply pose transformations, we
                are able to handle poses from face images in the wild. In
                addition, <b style="color: #76b900;">SPACE</b> is also able to generate missing details
                such as teeth, while other methods either fail or introduce
                artifacts. Our method even adds realistic head
                and shoulder motions when the audio has a breathing sound.
                <b style="color: #76b900;">SPACE</b> has smoother lip motions compared
                to prior works, which produce exaggerated and jerky motions.
                No other work allows as much controllability over the output video.
                Comparisions with prior work are shown in the videos below.
            </div>
        </div>
        </br>
        <table>
            <tr class="text-center" style="background-color: rgba(128, 128, 128, 0.2);">
                <td>Input image</td>
                <td><a href="https://hangz-nju-cuhk.github.io/projects/PC-AVS" target='_blank'>PC-AVS</a></td>
                <td><a href='https://people.umass.edu/~yangzhou/MakeItTalk/' target='_blank'>MakeItTalk</a></td>
                <td><a href='http://cvit.iiit.ac.in/research/projects/cvit-projects/a-lip-sync-expert-is-all-you-need-for-speech-to-lip-generation-in-the-wild/'
                        target='_blank'>Wav2Lip</a></td>
                <td><b style="color: #76b900;">SPACE</b> (ours)</td>
            </tr>
            <tr>
                <td>
                    <img src="data/comparison/id00419-ag7_GcN_rEM-00314.png">
                </td>
                <td colspan="4">
                    <video controls style="vertical-align: top;">
                        <source src="data/comparison/id00419-ag7_GcN_rEM-00314.mp4"" type=" video/mp4">
                    </video>
                </td>
            </tr>
            <tr>
                <td>
                    <img src="data/comparison/id03789-9alL5EAVFZU-00114.png">
                </td>
                <td colspan="4">
                    <video controls style="vertical-align: top;">
                        <source src="data/comparison/id03789-9alL5EAVFZU-00114.mp4"" type=" video/mp4">
                    </video>
                </td>
            </tr>
            <tr>
                <td>
                    <img src="data/comparison/id04862-4r-u7YAGLoA-00039.png">
                </td>
                <td colspan="4">
                    <video controls style="vertical-align: top;">
                        <source src="data/comparison/id04862-4r-u7YAGLoA-00039.mp4"" type=" video/mp4">
                    </video>
                </td>
            </tr>
            <tr>
                <td>
                    <img src="data/comparison/id08696-_ir7v67UliA-00339.png">
                </td>
                <td colspan="4">
                    <video controls style="vertical-align: top;">
                        <source src="data/comparison/id08696-_ir7v67UliA-00339.mp4"" type=" video/mp4">
                    </video>
                </td>
            </tr>
            <tr>
                <td>
                    <img src="data/comparison/id10306-5jsUg3uxG-E-00005.png">
                </td>
                <td colspan="4">
                    <video controls style="vertical-align: top;">
                        <source src="data/comparison/id10306-5jsUg3uxG-E-00005.mp4"" type=" video/mp4">
                    </video>
                </td>
            </tr>
            <tr class="text-center" style="background-color: rgba(128, 128, 128, 0.2);">
                <td>Input image</td>
                <td><a href=" https://hangz-nju-cuhk.github.io/projects/PC-AVS" target='_blank'>PC-AVS</a></td>
                <td><a href='https://people.umass.edu/~yangzhou/MakeItTalk/' target='_blank'>MakeItTalk</a></td>
                <td><a href='http://cvit.iiit.ac.in/research/projects/cvit-projects/a-lip-sync-expert-is-all-you-need-for-speech-to-lip-generation-in-the-wild/'
                        target='_blank'>Wav2Lip</a></td>
                <td><b style="color: #76b900;">SPACE</b> (ours)</td>
            </tr>
        </table>
        </br>
        <div class="row">
            <div class="col-md-12">
                Comparing the results from different methods, we can immediately notice a few issues:
                <ul>
                    <li>
                        <a href="https://hangz-nju-cuhk.github.io/projects/PC-AVS" target='_blank'>PC-AVS</a> tightly
                        crops the input image and changes the input pose. The face motion is rather jerky.
                    </li>
                    <li>
                        <a href='https://people.umass.edu/~yangzhou/MakeItTalk/' target='_blank'>MakeItTalk</a> has
                        poorer lip motion and
                        introduces artifacts in the output videos.
                        For example, in the bottom two videos, there are white patchy artifacts.
                    </li>
                    <li>
                        <a href='http://cvit.iiit.ac.in/research/projects/cvit-projects/a-lip-sync-expert-is-all-you-need-for-speech-to-lip-generation-in-the-wild/'
                            target='_blank'>Wav2Lip</a> was designed with dubbing in mind. It only moves the lips, while
                        the rest of the face remains still, producing unrealistic outputs.
                    </li>
                </ul>
                In the last column, we present results from <b style="color: #76b900;">SPACE</b>, which
                solves all the issues raised above. It handles a large variety of input poses, produces realistic lip
                motion, and high-quality outputs.
                <br>
            </div>
        </div>
        </br>
    </div>

    <!-- Method details. -->
    <hr style="max-width: 800px;">
    <div class="container" style="max-width: 800px;" id="Method">
        <div class="row">
            <div class="col-md-12">
                <h2>Method</h2>
                <h5 class="text-center">What makes <b style="color: #76b900;">SPACE</b> so controllable?</h5>
                <b style="color: #76b900;">SPACE</b> decomposes the task of speech to face animation into 3 stages, as
                shown in the below image:<br>
                1) Speech2Landmarks (S2L), 2) Landmarks2Latents (L2L), and 3) Video Synthesis. Predicting facial
                landmarks helps add
                modifications such as blinking. We can also apply any desired rotation, translation, and scaling to the
                3D facial landmarks. Instead of learning to generate a high-quality output image from facial landmarks,
                we use a state-of-the-art pretrained <a href="https://nvlabs.github.io/face-vid2vid/"
                    target="_blank">face-vid2vid</a>
                generator. This generator takes in the input image and latent keypoints that specify the required output
                pose and facial configuration. We thus train a facial landmark to latent keypoints network for the
                second stage. face-vid2vid latent keypoints can also be modified to change the eye gaze. In the final
                step, the pretrained generator produces \(512\times512\) pixel frames.
            </div>
        </div>
        <br><br>

        <img src="data/method/overview.png">
        <br><br>
        The videos below show the intermediate and final predictions of <b style="color: #76b900;">SPACE</b>.
        <br><br>

        <table>
            <tr class="text-center">
                <td style="background-color: rgba(255, 149, 0, 0.6);">Input</td>
                <td colspan="3" style="background-color: rgba(128, 128, 128, 0.4);">Intermediate predictions</td>
                <td style="background-color: rgba(56, 162, 34, 0.6);">Final</td>
            </tr>
            <tr class="text-center">
                <td style="background-color: rgba(255, 149, 0, 0.3)">Single Image</td>
                <td style="background-color: rgba(128, 128, 128, 0.2);">Normalized facial landmarks</td>
                <td style="background-color: rgba(128, 128, 128, 0.2);">Posed facial landmarks</td>
                <td style="background-color: rgba(128, 128, 128, 0.2);">Latent face-vid2vid keypoints</td>
                <td style="background-color: rgba(56, 162, 34, 0.3);">Animated output</td>
            </tr>
            <tr>
                <td>
                    <img src="data/intermediates/id00017-M6PYYNz3pac-00033.jpg">
                </td>
                <td colspan="4">
                    <video controls style="vertical-align: top;">
                        <source src="data/intermediates/id00017-M6PYYNz3pac-00033.mp4" type="video/mp4">
                    </video>
                </td>
            </tr>
            <tr>
                <td>
                    <img src="data/intermediates/id01460-2vJlUcWI2DQ-00012.jpg">
                </td>
                <td colspan="4">
                    <video controls style="vertical-align: top;">
                        <source src="data/intermediates/id01460-2vJlUcWI2DQ-00012.mp4" type="video/mp4">
                    </video>
                </td>
            </tr>
        </table>
        <br>

        <div class="row">
            <div class="col-md-12">
                <hr style="max-width: 800px;">
                <h5 class="text-center">Emotion control</h5>
                We condition both the Speech2Landmark and Landmark2Latent models on the emotion of the video frames
                using
                <a href="https://github.com/ethanjperez/film" target="_blank">FiLM</a> layers.
                For the S2L network, we use FiLM to modulate the audio features and the initial landmark input.
                For L2L, we apply FiLM on the audio, landmarks, and the initial latent keypoint input.
                For training, we use one-hot emotion labels when provided by the dataset, and a predicted per-frame
                probability
                distribution over the emotions when the ground-truth emotions are unavailable.
                At inference, we can provide the desired combination of emotion labels and their intensities as input,
                as shown in the video below.
            </div>
        </div>
        <br>

        <table style="width: 70%; margin: auto;">
            <tr class="text-center">
                <td style="background-color: rgba(128, 128, 128, 0.4);">Input image</td>
                <td style="background-color: rgba(56, 162, 34, 0.3);">0.5 Happy</td>
                <td style="background-color: rgba(56, 162, 34, 0.6);">1.0 Happy</td>
            </tr>
            <tr>
                <td style="background-color: rgba(128, 128, 128, 0.2);"> <img src="data/emotion/source.jpg"> </td>
                <td colspan="2">
                    <video controls style="vertical-align: top;">
                        <source src="data/emotion/video.mp4" type="video/mp4">
                    </video>
                </td>
            </tr>
            <tr class="text-center">
                <td style="background-color: rgba(128, 128, 128, 0.4);">Input image</td>
                <td style="background-color: rgba(255, 149, 0, 0.3);">0.5 Angry</td>
                <td style="background-color: rgba(255, 149, 0, 0.6);">1.0 Angry</td>
            </tr>
        </table>
        <br>

        <div class="row">
            <div class="col-md-12">
                <hr style="max-width: 800px;">
                <h5 class="text-center">Eye control &#8212; blinking and gaze</h5>
                By manipulating the intermediate facial landmarks corresponding to the eyes, we can introduce eye
                blinking motion. As face-vid2vid allows control over the eye gaze, we are also able to control the gaze
                of the output video.
            </div>
        </div>
        <br>

        <table style="width: 70%; margin: auto;">
            <tr class="text-center">
                <td style="background-color: rgba(128, 128, 128, 0.4);">Input image</td>
                <td style="background-color: rgba(56, 162, 34, 0.3);">Blinking</td>
                <td style="background-color: rgba(56, 162, 34, 0.6);">Gaze change</td>
            </tr>
            <tr>
                <td> <img src="data/eye/id01333-QeRAaXF37a8-00183.png"> </td>
                <td>
                    <video controls style="vertical-align: top;">
                        <source src="data/eye/id01333-QeRAaXF37a8-00183-blink.mp4" type="video/mp4">
                    </video>
                </td>
                <td>
                    <video controls style="vertical-align: top;">
                        <source src="data/eye/id01333-QeRAaXF37a8-00183-gaze.mp4" type="video/mp4">
                    </video>
                </td>
            </tr>
            <tr>
                <td> <img src="data/eye/id00081-ICIH8uZngXw-00072.png"> </td>
                <td>
                    <video controls style="vertical-align: top;">
                        <source src="data/eye/id00081-ICIH8uZngXw-00072-blink.mp4" type="video/mp4">
                    </video>
                </td>
                <td>
                    <video controls style="vertical-align: top;">
                        <source src="data/eye/id00081-ICIH8uZngXw-00072-gaze.mp4" type="video/mp4">
                    </video>
                </td>
            </tr>
        </table>

    </div>
    <br>

    <!-- Summary. -->
    <hr style="max-width: 800px;">
    <div class="container" style="max-width: 800px;" id="Summary">
        <div class="row">
            <div class="col-md-12">
                <h2>Summary</h2>
                <ul>
                    <li><b style="color: #76b900;">SPACE</b> is a powerful tool for animating a facial image using just
                        speech input.</li>
                    <li>Existing methods perform poorly when the input face has large head rotations. Some require tight
                        face crops, or animate just the lips.
                        <b style="color: #76b900;">SPACE</b> animates the entire face and can even generate realistic
                        head pose sequences.
                    </li>
                    <li><b style="color: #76b900;">SPACE</b> offers unprecedented controllability of the outputs
                        &#8212; head pose, emotion label and intensity,
                        blinking, and eye gaze control.</li>
                    <li>Unlike prior work, <b style="color: #76b900;">SPACE</b> produces high-quality photorealistic
                        and temporally stable outputs at \(512\times512\) resolution by using a pretrained face-vid2vid
                        generator.</li>

                </ul>
            </div>
        </div>
    </div>

    <!-- Citation. -->
    <hr style="max-width: 800px;">
    <div class="container" style="max-width: 800px;">
        <div class="row">
            <div class="col-md-12">
                <h2>Citation</h2>
            </div>
        </div>
        <div class="code-box-copy" style="font-size: 0.9rem !important; max-width: 800px; margin: 0 auto;">
            <button class="code-box-copy__btn" data-clipboard-target="#citation" title="Copy"
                style="opacity: 1;"></button>
            <pre><code class="language-bib" style="font-size: 0.9rem;" id="citation">@article{gururani2022SPACE,
  title={{SPACE: Speech-driven Portrait Animation with Controllable Expression}},
  author={Siddharth Gururani and Arun Mallya and Ting-Chun Wang and Rafael Valle and Ming-Yu Liu},
  journal={arXiv preprint arXiv:2211.09809},
  year={2022}
}</code></pre>
        </div>
    </div>


    <footer class="text-">
        <div class="container">
            <p class="float-right">
                <a href="#">Back to top</a>
            </p>
        </div>
    </footer>

    <!-- Bootstrap core JavaScript
        ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
        integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
        crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
        integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
        crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
        integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
        crossorigin="anonymous"></script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <script src="https://cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs/prism.min.js"></script>
    <script
        src="https://cdn.jsdelivr.net/combine/gh/jablonczay/code-box-copy/clipboard/clipboard.min.js,gh/jablonczay/code-box-copy/code-box-copy/js/code-box-copy.min.js"></script>
    <script src="https://saswatpadhi.github.io/prismjs-bibtex/prism-bibtex.min.js"></script>
    <script>
        (function ($) {
            $('.code-box-copy').codeBoxCopy();
        })(jQuery);
    </script>
</body>

</html>